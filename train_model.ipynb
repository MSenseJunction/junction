{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfd1732",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# train_model.py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "CSV_PATH = \"synthetic_wsht_weather_migraine_prob_600days_hourly_FIXED.csv\"\n",
    "FEATURES = [\"workload_0_10\", \"stress_0_10\", \"hrv_rmssd_ms\"]\n",
    "TARGET_LABEL = \"migraine_prob_next_hour\"\n",
    "SEQ_LEN = 24\n",
    "RANDOM_SEED = 123\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "\n",
    "df = pd.read_csv(CSV_PATH, parse_dates=[\"timestamp\"])\n",
    "df = df.sort_values(\"timestamp\").reset_index(drop=True)\n",
    "df = df[~df[TARGET_LABEL].isna()].reset_index(drop=True)\n",
    "df[TARGET_LABEL] = df[TARGET_LABEL].astype(int)\n",
    "\n",
    "def build_sequences(frame, features, seq_len):\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(frame[features])\n",
    "    joblib.dump(scaler, \"scaler.pkl\")  # save scaler\n",
    "\n",
    "    feat = scaler.transform(frame[features])\n",
    "    y = frame[TARGET_LABEL].to_numpy().astype(int)\n",
    "    X_list, y_list = [], []\n",
    "    for end in range(seq_len, len(frame)):\n",
    "        start = end - seq_len\n",
    "        X_list.append(feat[start:end, :])\n",
    "        y_list.append(y[end])\n",
    "    return np.array(X_list), np.array(y_list)\n",
    "\n",
    "X, y = build_sequences(df, FEATURES, SEQ_LEN)\n",
    "\n",
    "# split chronologically\n",
    "N = len(X)\n",
    "train_n = int(N * 0.7)\n",
    "val_n   = int(N * 0.15)\n",
    "X_train, y_train = X[:train_n], y[:train_n]\n",
    "X_val,   y_val   = X[train_n:train_n+val_n], y[train_n:train_n+val_n]\n",
    "X_test,  y_test  = X[train_n+val_n:], y[train_n+val_n:]\n",
    "\n",
    "def make_model(input_len, input_dim):\n",
    "    inputs = keras.Input(shape=(input_len, input_dim))\n",
    "    x = layers.Masking(mask_value=0.0)(inputs)\n",
    "    x = layers.LSTM(64)(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(32, activation=\"relu\")(x)\n",
    "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(1e-3),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[keras.metrics.AUC(name=\"auc\"), \"accuracy\"],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "model = make_model(SEQ_LEN, len(FEATURES))\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor=\"val_auc\", mode=\"max\", factor=0.5, patience=3, verbose=1),\n",
    "    keras.callbacks.EarlyStopping(monitor=\"val_auc\", mode=\"max\", patience=8, restore_best_weights=True, verbose=1),\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=50,\n",
    "    batch_size=64,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "print(\"Test evaluation:\", model.evaluate(X_test, y_test, verbose=0))\n",
    "model.save(\"lstm_migraine_model.h5\")\n",
    "print(\"Saved lstm_migraine_model.h5 and scaler.pkl\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
